{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from serenity_sdk.client import load_local_config\n",
    "from serenity_sdk.client import SerenityClient\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "pd.set_option('display.max_rows', 20)\n",
    "\n",
    "config_id = 'athansor'  # Use your own `config_id`\n",
    "config = load_local_config(config_id)\n",
    "\n",
    "client = SerenityClient(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a simple portfolio and some unit allocations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio = {\n",
    "    'ADA': 1000000,\n",
    "    'BTC': 100,\n",
    "    'ETH': 1000,\n",
    "    'XRP': 2000000,\n",
    "    'ALGO': 1500000,\n",
    "    'SOL': 10000,\n",
    "    'DOT': 50000\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, fetch the asset master and map our portfolio to the Serenity internal IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refdata_response = client.call_api(\n",
    "    api_group='refdata',\n",
    "    api_path='/asset/summaries'\n",
    ")\n",
    "\n",
    "df = pd.json_normalize(refdata_response['assetSummary']).set_index('assetId')\n",
    "asset_master_df = df.filter(['assetId', 'nativeSymbol'])\n",
    "ids_dict = {asset_master_df[asset_master_df['nativeSymbol'] == s].index[0]: s for s in portfolio.keys()}\n",
    "portfolio_ids = {asset_master_df[asset_master_df.nativeSymbol == id].index[0]:qty for (id, qty) in portfolio.items()}\n",
    "\n",
    "portfolio_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use these Serenity asset IDs to build the query for the Serenity client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_input = {}\n",
    "portfolio_input['assetPositions'] = [{'assetId': item[0], 'quantity': item[1]} for item in portfolio_ids.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in this exercise we do a point in time analysis, which is how the [Serenity API](https://developer.athansor.cloudwall.network/api/serenity-risk-services) is supposed to be used. If you need a timeseries of these data, you will need to loop through a set of dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'as_of_date': '2021-07-01'}\n",
    "\n",
    "risk_attribution_json = client.call_api(\n",
    "    api_group='risk',\n",
    "    api_path='/compute/attribution',\n",
    "    body_json=portfolio_input,\n",
    "    params=params,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The API response will be a JSON file, with the information of the request, reference date, and the risk attribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_attribution_json.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially, we want to see how much of the portfolio volatility is explained by the risk factors, and what is the specific (idiosyncratic) risk. This latter is the part of the portfolio volatility specific to the assets in the portfolio. This means they cannot be explained by the used risk factors. We usually want to see most of the risk explained by the risk factors, which means the sources of risk in our portfolio are known. We can do this decomposition for both volatility and for the variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_risk = pd.DataFrame.from_dict(risk_attribution_json['totalRisk'])\n",
    "total_risk_table = total_risk.style.format(\"{:.1%}\").bar()\n",
    "\n",
    "total_risk_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to get marginal risk, which represents the percentage contribution of each asset’s volatility to the portfolio volatility. We can use this to understand what is the marginal contribution to the risk of each asset. *Marginal* means that it’s the impact on the portfolio volatility of a % increase of a certain asset’s weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marginal_risk = pd.DataFrame.from_dict(\n",
    "    risk_attribution_json['assetMarginalRisk'])\n",
    "marginal_risk.set_index('assetId', inplace=True)\n",
    "marginal_risk.set_index(marginal_risk.index.map(ids_dict), inplace=True)\n",
    "marginal_risk_table = marginal_risk.style.format(\"{:.1%}\").bar()\n",
    "\n",
    "marginal_risk_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can weigh the marginal contribution by the asset weights to obtain the absolute contribution to the portfolio volatility of each asset. We can use this to understand how each asset is contributing to the volatility of the portfolio, and then we can make portfolio allocation decisions based on this information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contribution_risk_absolute_byasset = pd.DataFrame.from_dict(\n",
    "    risk_attribution_json['absoluteContributionRisk']['byAsset'])\n",
    "contribution_risk_absolute_byasset.set_index('assetId', inplace=True)\n",
    "contribution_risk_absolute_byasset.set_index(contribution_risk_absolute_byasset.index.map(ids_dict), inplace=True)\n",
    "contribution_risk_absolute_byasset_table = contribution_risk_absolute_byasset.style.format(\"{:.1%}\").bar()\n",
    "\n",
    "contribution_risk_absolute_byasset_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contribution_risk_absolute_byasset = pd.DataFrame.from_dict(\n",
    "    risk_attribution_json['absoluteContributionRisk']['byAsset'])\n",
    "contribution_risk_absolute_byasset.set_index('assetId', inplace=True)\n",
    "contribution_risk_absolute_byasset.set_index(contribution_risk_absolute_byasset.index.map(ids_dict), inplace=True)\n",
    "contribution_risk_absolute_byasset_table = contribution_risk_absolute_byasset.style.format(\"{:.1%}\").bar()\n",
    "\n",
    "contribution_risk_absolute_byasset_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the absolute risk contribution sums up to the total volatility of the portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contribution_risk_absolute_byasset.sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the derivation of this metric, we can use it to back-off our portfolio weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_weights = contribution_risk_absolute_byasset[['factorRisk']] / marginal_risk[['factorRisk']]\n",
    "portfolio_weights.rename(columns={\"factorRisk\": 'weights'}, inplace=True)\n",
    "portfolio_weights_table = portfolio_weights.style.format(\"{:.1%}\").bar()\n",
    "\n",
    "portfolio_weights_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a similar way we can decompose the portfolio *variance* to obtain the relative contribution to the portfolio risk. This helps to understand how much, in percentage terms, each asset is contributing to Factor, Specific and Total risk of the portfolio in terms of the variance. If compared to the absolute contribution, here we use variance because it’s additive, while volatility is not additive. This can help us to see if a certain asset has e.g. more Specific risk, which we might want to diversify or get exposure to. *Relative* here means that we are making a comparison to the other assets in the portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contribution_risk_relative_byasset = pd.DataFrame.from_dict(\n",
    "    risk_attribution_json['relativeContributionRisk']['byAsset'])\n",
    "contribution_risk_relative_byasset.set_index('assetId', inplace=True)\n",
    "contribution_risk_relative_byasset.set_index(contribution_risk_relative_byasset.index.map(ids_dict), inplace=True)\n",
    "contribution_risk_relative_byasset_table = contribution_risk_relative_byasset.style.format(\"{:.1%}\").bar()\n",
    "\n",
    "contribution_risk_relative_byasset_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here we can also show that this metric sums up to the total portfolio risk (in terms of variance this time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contribution_risk_relative_byasset.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_risk_test = total_risk.loc['factorRisk']['variance'] / total_risk.loc['totalRisk']['variance']\n",
    "specific_risk_test = total_risk.loc['specificRisk']['variance'] / total_risk.loc['totalRisk']['variance']\n",
    "\n",
    "print(factor_risk_test.round(10) == contribution_risk_relative_byasset.sum(axis=0)['factorRisk'].round(10))\n",
    "print(specific_risk_test.round(10) == contribution_risk_relative_byasset.sum(axis=0)['specificRisk'].round(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a way to get these metrics by sector. In this model we used the [DACS sector taxonomy](https://www.coindesk.com/static/coindesk-dacs/), with three sub-levels. The `parentSector` column tells us if the specific row has a parent sector. You can extract the full taxonomy from the `/sector/taxonomies` endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contribution_risk_relative_bysector = pd.DataFrame.from_dict(\n",
    "    risk_attribution_json['relativeContributionRisk']['bySector'])\n",
    "    \n",
    "contribution_risk_relative_bysector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can also get the marginal, absolute, and relative contributions to the portfolio risk from each of the factors. The definitions of these metrics are the same as above. Here you can also get the factor exposure, which is the dot product between asset weights and each asset's factor loading. This, in practice, gives you the portfolio factor exposure in the selected point in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_risk = pd.DataFrame.from_dict(risk_attribution_json['factorRisk'])\n",
    "factor_risk = factor_risk.set_index('factor').transpose()\n",
    "factor_risk_table = factor_risk.style.format(\"{:.1%}\").bar()\n",
    "\n",
    "factor_risk_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the relative contribution sums to 100%, while the absolute contribution sums to the portfolio volatility explained by the factor risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_risk.loc['relativeContribution'].sum().round(10) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_risk.loc['absoluteContribution'].sum().round(10) == total_risk['volatility']['factorRisk'].round(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the derivations, we get the relative risk contribution from the absolute contribution. And we get the absolute contribution from the marginal contribution and from the factor exposure. If you want to know how to derive the marginal contribution, follow along, as it's explained later in this Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_risk.loc['absoluteContribution'] / total_risk['volatility']['factorRisk'] == factor_risk.loc['relativeContribution']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_risk.loc['marginalContribution'] * factor_risk.loc['factorExposure'] == factor_risk.loc['absoluteContribution'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also aggregate the portfolio factor exposures by sector. This is useful to see how each sector exposure in our portfolio is contributing to each portfolio factor exposure. You can see that the sum of each Factor, Specific, or Total risk across the sectors will give you the portfolio factor exposure for each factor (we'll leave this exercise to you)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sector_factors = pd.DataFrame.from_dict(risk_attribution_json['sectorFactorExposure'])\n",
    "df = sector_factors.explode('factorRisk').reset_index(drop=True)\n",
    "df = df.join(pd.json_normalize(df.factorRisk)).drop(columns=['factorRisk'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the Risk API you can also get the intermediate results that go into the factor model. Here you can, for instance, see the Factor-based asset covariance matrix and the residuals covariance matrix. These are fetched for the full universe, and we then subset it to the example portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assetcov_response = client.call_api(\n",
    "    api_group='risk',\n",
    "    api_path='/asset/covariance',\n",
    "    params=params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_df = pd.DataFrame.from_dict(assetcov_response['matrix']).dropna()\n",
    "cov_df = cov_df[cov_df['assetId1'].isin(ids_dict.keys()) & cov_df['assetId2'].isin(ids_dict.keys())]\n",
    "cov_df = cov_df.pivot(index='assetId1', columns='assetId2', values='value')\n",
    "cov_df.set_index(cov_df.index.map(ids_dict), inplace=True)\n",
    "cov_df.columns = cov_df.columns.map(ids_dict)\n",
    "sns.heatmap(cov_df, cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescov_response = client.call_api('risk', '/asset/residual/covariance', params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_cov_df = pd.DataFrame.from_dict(rescov_response['matrix']).dropna()\n",
    "res_cov_df = res_cov_df[res_cov_df['assetId1'].isin(ids_dict.keys()) & res_cov_df['assetId2'].isin(ids_dict.keys())]\n",
    "res_cov_df = res_cov_df.pivot(index='assetId1', columns='assetId2', values='value')\n",
    "res_cov_df.set_index(res_cov_df.index.map(ids_dict), inplace=True)\n",
    "res_cov_df.columns = res_cov_df.columns.map(ids_dict)\n",
    "\n",
    "res_cov_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also fetch the factor returns that go into our risk factor model, in case you want to see how each factor performs at the selected point in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_returns_response = client.call_api(\n",
    "    api_group='risk',\n",
    "    api_path='/factor/returns',\n",
    "    params=params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_returns = pd.DataFrame.from_dict(factor_returns_response['factorReturns']).pivot(index='closeDate', columns='factor', values='value')\n",
    "factor_returns.style.format(\"{:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get the factor exposures of each asset in your portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_exposures_response = client.call_api(\n",
    "    api_group='risk',\n",
    "    api_path='/asset/factor/exposures',\n",
    "    params=params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_exposures = pd.DataFrame.from_dict(factor_exposures_response['matrix'])\n",
    "factor_exposures = factor_exposures[factor_exposures['assetId'].isin(ids_dict.keys())]\n",
    "factor_exposures = factor_exposures.pivot(index='assetId', columns='factor', values='value')\n",
    "factor_exposures.set_index(factor_exposures.index.map(ids_dict), inplace=True)\n",
    "\n",
    "factor_exposures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use this along with the portfolio weights to get the portfolio factor exposure for each factor. This is an example for the Liquidity factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(portfolio_weights['weights'], factor_exposures['liquidity']).round(10) == factor_risk.loc['factorExposure']['liquidity'].round(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Earlier we've mentioned that we can also derive our marginal risk factor contribution. For this, we need to fetch the factor covariance matrix, which is the covariance matrix derived from the factor returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factorcov_response = client.call_api(\n",
    "    api_group='risk',\n",
    "    api_path='/factor/covariance',\n",
    "    params=params\n",
    ")\n",
    "\n",
    "fac_cov_df = pd.DataFrame.from_dict(factorcov_response['matrix']).dropna()\n",
    "fac_cov_df = fac_cov_df.pivot(index='factor1', columns='factor2', values='value')\n",
    "sns.heatmap(fac_cov_df, cmap='YlGnBu')\n",
    "\n",
    "fac_cov_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fac_cov_df.loc['liquidity'] @ factor_risk.loc['factorExposure'] / total_risk['volatility']['factorRisk'] == factor_risk.loc['marginalContribution']['liquidity']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "c62c89f21494fa5f008df13ad65ebe7508ff02105720a664dda24b54d542cf2e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
